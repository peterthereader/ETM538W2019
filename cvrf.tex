\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Blood Donation Classification Prediction},
            pdfauthor={Andey Nunes},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Blood Donation Classification Prediction}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \subtitle{using Cross Validation with Random Forest}
  \author{Andey Nunes}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{3/2/2019}


\begin{document}
\maketitle

\section{Data Description}\label{data-description}

Our group is entered into a competitiion for a classification problem:
\url{https://www.drivendata.org/competitions/2/warm-up-predict-blood-donations/}

\begin{quote}
The business question is: using data about student blood donations, can
we predict if a student will donate blood next time?
\end{quote}

The competition specifies the training and test files, so we do not need
to set aside test data. First we load and inspect the training set for
structure, variable types, and pairwise correlations.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"projectdata.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Missing column names filled in: 'X1' [1]
\end{verbatim}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   X1 = col_double(),
##   `Months since Last Donation` = col_double(),
##   `Number of Donations` = col_double(),
##   `Total Volume Donated (c.c.)` = col_double(),
##   `Months since First Donation` = col_double(),
##   `Made Donation in March 2007` = col_double()
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(training)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Observations: 576
## Variables: 6
## $ X1                            <dbl> 619, 664, 441, 160, 358, 335, 47...
## $ `Months since Last Donation`  <dbl> 2, 0, 1, 2, 1, 4, 2, 1, 5, 0, 2,...
## $ `Number of Donations`         <dbl> 50, 13, 16, 20, 24, 4, 7, 12, 46...
## $ `Total Volume Donated (c.c.)` <dbl> 12500, 3250, 4000, 5000, 6000, 1...
## $ `Months since First Donation` <dbl> 98, 28, 35, 45, 77, 4, 14, 35, 9...
## $ `Made Donation in March 2007` <dbl> 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,...
\end{verbatim}

The variable \texttt{X1} has 576 unique entries and is therefore likely
to be a student or patient ID number. We can ignore it for modeling
purposes. I'm also going to shorten the variable names as follows:

\begin{itemize}
\tightlist
\item
  \texttt{Months\ since\ Last\ Donation} is renamed \texttt{recency} to
  indicate how many months ago the last donation event was
\item
  \texttt{Months\ since\ First\ Donation} is renamed \texttt{time} to
  indicate the total time span in months since the first donation event
\item
  \texttt{Number\ of\ Donations} is renamed \texttt{frequency}
\item
  \texttt{Total\ Volume\ Donated\ (c.c.)} is renamed \texttt{volume} the
  original data set library makes note that this field indicates the
  monetary measure being used for the business case
\item
  \texttt{Made\ Donation\ in\ March\ 2007} is renamed \texttt{target}
  and is the binary variable that we are trying to predict/classify
\end{itemize}

** Correlation Matrix of Blood Donation Data **

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training <-}\StringTok{ }\NormalTok{training[,}\OperatorTok{-}\DecValTok{1}\NormalTok{]}

\KeywordTok{names}\NormalTok{(training) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"recency"}\NormalTok{, }\StringTok{"freq"}\NormalTok{, }\StringTok{"vol"}\NormalTok{, }\StringTok{"time"}\NormalTok{, }\StringTok{"target"}\NormalTok{)}

\NormalTok{training_mat <-}\StringTok{ }\KeywordTok{data.matrix}\NormalTok{(training, }\DataTypeTok{rownames.force =}\NormalTok{ T)}

\NormalTok{corr_mat <-}\StringTok{ }\KeywordTok{cor}\NormalTok{(training_mat)}

\KeywordTok{corrplot.mixed}\NormalTok{(corr_mat)}
\end{Highlighting}
\end{Shaded}

\includegraphics{cvrf_files/figure-latex/correlations-1.pdf}

Here we can see that frequency of donation and the total blood volume
are perfectly positively correlated. We can therefore ignore the total
blood volume variable since all of the information will be captured and
passed along to our algorithms in the using the variables measured in
months and the donation frequency.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training <-}\StringTok{ }\KeywordTok{select}\NormalTok{(training, }\OperatorTok{-}\NormalTok{vol)}
\end{Highlighting}
\end{Shaded}

\section{Cross Validation Folds \&
Splits}\label{cross-validation-folds-splits}

Using the training data, we will create a 5-fold cross-validation split
tibble. This will set us up to itertively generate multiple models on
our new train/validation subsets.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# using the rsample library}
\NormalTok{cv_split <-}\StringTok{ }\KeywordTok{vfold_cv}\NormalTok{(training, }\DataTypeTok{v =} \DecValTok{5}\NormalTok{)}
\CommentTok{# cv_split  # uncomment the front of this line if you want to preview}
\end{Highlighting}
\end{Shaded}

The \texttt{cv\_split} object has five rows and two columns. The first
column, \texttt{splits}, is a list column containing the training and
validation data. The second column is a character vector containing the
fold id generated by the \texttt{vfold\_cv()} function. We can iterate
over the \texttt{splits} column and extract the train and validation
columns

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv_data <-}\StringTok{ }\NormalTok{cv_split }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{train =} \KeywordTok{map}\NormalTok{(splits, }\OperatorTok{~}\KeywordTok{training}\NormalTok{(.x)),}
          \DataTypeTok{validate =} \KeywordTok{map}\NormalTok{(splits, }\OperatorTok{~}\KeywordTok{testing}\NormalTok{(.x)))}
\KeywordTok{glimpse}\NormalTok{(cv_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Observations: 5
## Variables: 4
## $ splits   <list> [<rsplit[460 x 116 x 576 x 4]>, <rsplit[461 x 115 x ...
## $ id       <chr> "Fold1", "Fold2", "Fold3", "Fold4", "Fold5"
## $ train    <list> [<tbl_df[460 x 4]>, <tbl_df[461 x 4]>, <tbl_df[461 x...
## $ validate <list> [<tbl_df[116 x 4]>, <tbl_df[115 x 4]>, <tbl_df[115 x...
\end{verbatim}

We've just created two new list columns containing the data that we can
now train and validate models over.

\section{Model preparation}\label{model-preparation}

\subsubsection{linear model}\label{linear-model}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv_models_lm <-}\StringTok{ }\NormalTok{cv_data }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{lm_model =} \KeywordTok{map}\NormalTok{(train, }\OperatorTok{~}\KeywordTok{lm}\NormalTok{(}\DataTypeTok{formula =}\NormalTok{ target}\OperatorTok{~}\NormalTok{., }\DataTypeTok{data =}\NormalTok{ .x)))}
\end{Highlighting}
\end{Shaded}

\subsubsection{knn ?}\label{knn}

\subsubsection{random forest}\label{random-forest}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Build a random forest model for each fold}
\NormalTok{cv_models_rf <-}\StringTok{ }\NormalTok{cv_data }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{rf_model =} \KeywordTok{map}\NormalTok{(train, }\OperatorTok{~}\KeywordTok{ranger}\NormalTok{(}\DataTypeTok{formula =}\NormalTok{ target}\OperatorTok{~}\NormalTok{., }\DataTypeTok{data =}\NormalTok{ .x,}
                                    \DataTypeTok{num.trees =} \DecValTok{100}\NormalTok{, }\DataTypeTok{seed =} \DecValTok{123}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\section{Model evaluation}\label{model-evaluation}

The \emph{cross-validation model evaluation process} follows the same
general set of steps iterated over each fold: 1. extract the actual
target values from the validation set 2. use the models to make target
predictions that will be compared to the actual target 3. for each fold,
calculate the Mean Absolute Error (\texttt{MAE}) where \$ MAE =
\frac{\sum^n_{i=1}|Actual_i - Predicted_i|}{n} \$ 4. Take the average
over all MAE values to determine with model performs best on these sets
of training \& validation splits

\subsubsection{linear model}\label{linear-model-1}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# extract actual values}
\NormalTok{cv_prep_lm <-}\StringTok{ }\NormalTok{cv_models_lm }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{validate_actual =} \KeywordTok{map}\NormalTok{(validate, }\OperatorTok{~}\NormalTok{.x}\OperatorTok{$}\NormalTok{target),}
          \DataTypeTok{validate_predicted =} \KeywordTok{map2}\NormalTok{(}\DataTypeTok{.x =}\NormalTok{ lm_model, }\DataTypeTok{.y =}\NormalTok{ validate, }
                                    \OperatorTok{~}\KeywordTok{predict}\NormalTok{(.x, .y)))}

\CommentTok{# the function mae() is from library(Metrics)}
\CommentTok{# Calculate the mean absolute error for each validate fold }
\NormalTok{cv_eval_lm <-}\StringTok{ }\NormalTok{cv_prep_lm }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{validate_mae =} \KeywordTok{map2_dbl}\NormalTok{(}\DataTypeTok{.x =}\NormalTok{ validate_actual, }
                                 \DataTypeTok{.y =}\NormalTok{ validate_predicted, }
                                 \OperatorTok{~}\KeywordTok{mae}\NormalTok{(}\DataTypeTok{actual =}\NormalTok{ .x, }\DataTypeTok{predicted =}\NormalTok{ .y)))}

\CommentTok{# Print the validate_mae column}
\NormalTok{cv_eval_lm}\OperatorTok{$}\NormalTok{validate_mae}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    1    2    3    4    5 
## 0.32 0.32 0.35 0.33 0.32
\end{verbatim}

The average mean absolute error across all linear models was 0.33.

Lets see how other models compared.

\subsubsection{knn ?}\label{knn-1}

\subsubsection{random forest}\label{random-forest-1}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Generate predictions using the random forest model}
\NormalTok{cv_prep_rf <-}\StringTok{ }\NormalTok{cv_models_rf }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{validate_actual =} \KeywordTok{map}\NormalTok{(validate, }\OperatorTok{~}\NormalTok{.x}\OperatorTok{$}\NormalTok{target),}
         \DataTypeTok{validate_predicted =} \KeywordTok{map2}\NormalTok{(}\DataTypeTok{.x =}\NormalTok{ rf_model, }\DataTypeTok{.y =}\NormalTok{ validate, }\OperatorTok{~}\KeywordTok{predict}\NormalTok{(.x, .y)}\OperatorTok{$}\NormalTok{predictions))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Calculate validate MAE for each fold}
\NormalTok{cv_eval_rf <-}\StringTok{ }\NormalTok{cv_prep_rf }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{validate_mae =} \KeywordTok{map2_dbl}\NormalTok{(validate_actual, validate_predicted, }\OperatorTok{~}\KeywordTok{mae}\NormalTok{(}\DataTypeTok{actual =}\NormalTok{ .x, }\DataTypeTok{predicted =}\NormalTok{ .y)))}

\CommentTok{# Print the validate_mae column}
\NormalTok{cv_eval_rf}\OperatorTok{$}\NormalTok{validate_mae}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    1    2    3    4    5 
## 0.30 0.31 0.30 0.31 0.29
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Calculate the mean of validate_mae column}
\KeywordTok{mean}\NormalTok{(cv_eval_rf}\OperatorTok{$}\NormalTok{validate_mae)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3
\end{verbatim}

Tune hyper-parameters

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Prepare for tuning cross validation folds by varying mtry}
\NormalTok{cv_tune <-}\StringTok{ }\NormalTok{cv_data }\OperatorTok{%>%}\StringTok{ }
\StringTok{   }\KeywordTok{crossing}\NormalTok{(}\DataTypeTok{mtry =} \DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{)}

\CommentTok{# Build a model for each fold & mtry combination}
\NormalTok{cv_model_tunerf <-}\StringTok{ }\NormalTok{cv_tune }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{rf_model =} 
            \KeywordTok{map2}\NormalTok{(}\DataTypeTok{.x =}\NormalTok{ train, }\DataTypeTok{.y =}\NormalTok{ mtry, }
                 \OperatorTok{~}\KeywordTok{ranger}\NormalTok{(}\DataTypeTok{formula =}\NormalTok{ target}\OperatorTok{~}\NormalTok{., }\DataTypeTok{data =}\NormalTok{ .x, }
                         \DataTypeTok{mtry =}\NormalTok{ .y, }\DataTypeTok{num.trees =} \DecValTok{100}\NormalTok{, }\DataTypeTok{seed =} \DecValTok{123}\NormalTok{)))}

\KeywordTok{glimpse}\NormalTok{(cv_model_tunerf) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Observations: 15
## Variables: 6
## $ splits   <list> [<rsplit[460 x 116 x 576 x 4]>, <rsplit[460 x 116 x ...
## $ id       <chr> "Fold1", "Fold1", "Fold1", "Fold2", "Fold2", "Fold2",...
## $ train    <list> [<tbl_df[460 x 4]>, <tbl_df[460 x 4]>, <tbl_df[460 x...
## $ validate <list> [<tbl_df[116 x 4]>, <tbl_df[116 x 4]>, <tbl_df[116 x...
## $ mtry     <int> 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3
## $ rf_model <list> [<0.2360, 0.4114, 0.5433, 0.7181, 0.6184, 0.5692, 0....
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Generate validate predictions for each model}
\NormalTok{cv_prep_tunerf <-}\StringTok{ }\NormalTok{cv_model_tunerf }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{rf_validate_actual =} \KeywordTok{map}\NormalTok{(validate, }\OperatorTok{~}\NormalTok{.x}\OperatorTok{$}\NormalTok{target),}
     \DataTypeTok{rf_validate_predicted =} \KeywordTok{map2}\NormalTok{(}\DataTypeTok{.x =}\NormalTok{ rf_model, }\DataTypeTok{.y =}\NormalTok{ validate, }\OperatorTok{~}\KeywordTok{predict}\NormalTok{(.x, .y)}\OperatorTok{$}\NormalTok{predictions))}

\CommentTok{# Calculate validate MAE for each fold and mtry combination}
\NormalTok{cv_eval_tunerf <-}\StringTok{ }\NormalTok{cv_prep_tunerf }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{rf_validate_mae =} \KeywordTok{map2_dbl}\NormalTok{(}\DataTypeTok{.x =}\NormalTok{ rf_validate_actual, }\DataTypeTok{.y =}\NormalTok{ rf_validate_predicted, }\OperatorTok{~}\KeywordTok{mae}\NormalTok{(}\DataTypeTok{actual =}\NormalTok{ .x, }\DataTypeTok{predicted =}\NormalTok{ .y)))}

\CommentTok{# Calculate the mean validate_mae for each mtry used  }
\NormalTok{cv_eval_tunerf }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(mtry) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{rf_mean_mae =} \KeywordTok{mean}\NormalTok{(rf_validate_mae))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##    mtry rf_mean_mae
##   <int>       <dbl>
## 1     1       0.303
## 2     2       0.299
## 3     3       0.301
\end{verbatim}

Selected random forest model with the lowest average mae

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{best <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(cv_eval_tunerf, rf_validate_mae }\OperatorTok{==}\StringTok{ }\KeywordTok{min}\NormalTok{(cv_eval_tunerf}\OperatorTok{$}\NormalTok{rf_validate_mae))}
\end{Highlighting}
\end{Shaded}

Use these parameters to traing our best rf model.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Build the model using all training data and the best performing parameter}
\NormalTok{best_model <-}\StringTok{ }\KeywordTok{ranger}\NormalTok{(}\DataTypeTok{formula =}\NormalTok{ target}\OperatorTok{~}\NormalTok{., }\DataTypeTok{data =}\NormalTok{ training,}
                     \DataTypeTok{mtry =} \DecValTok{3}\NormalTok{, }\DataTypeTok{num.trees =} \DecValTok{100}\NormalTok{, }\DataTypeTok{seed =} \DecValTok{123}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Model Output on Test Data}\label{model-output-on-test-data}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_data <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"project test data.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Missing column names filled in: 'X1' [1]
\end{verbatim}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   X1 = col_double(),
##   `Months since Last Donation` = col_double(),
##   `Number of Donations` = col_double(),
##   `Total Volume Donated (c.c.)` = col_double(),
##   `Months since First Donation` = col_double()
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(test_data) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{, }\StringTok{"recency"}\NormalTok{, }\StringTok{"freq"}\NormalTok{, }\StringTok{"vol"}\NormalTok{, }\StringTok{"time"}\NormalTok{)}
\CommentTok{# remove id}
\NormalTok{test_data <-}\StringTok{ }\NormalTok{test_data[,}\OperatorTok{-}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Predict life_expectancy for the testing_data}
\NormalTok{test_predicted <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(best_model, test_data)}\OperatorTok{$}\NormalTok{predictions}
\end{Highlighting}
\end{Shaded}

\section{Discussion}\label{discussion}

\section{References}\label{references}

Data is courtesy of Yeh, I-Cheng via the UCI Machine Learning repository
(\url{https://archive.ics.uci.edu/ml/datasets/Blood+Transfusion+Service+Center})

\url{https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.names}

Code examples were borrowed from DataCamp course material presented by
Dmitriy Gorenshteyn, ``Machine Learning in the Tidyverse''
\url{https://www.datacamp.com/courses/machine-learning-in-the-tidyverse}

\section{Appendix}\label{appendix}


\end{document}
